# HyperSDK Deployment Guide

**Version**: 0.2.0
**Date**: 2026-01-20
**Status**: Production Ready

---

## ðŸŽ¯ Overview

This deployment guide covers the complete installation and configuration of HyperSDK with all Phase 1-4 features:

- âœ… **Phase 1**: Connection Pooling, Webhook Integration
- âœ… **Phase 2**: OVA Format, Compression, Schedule Persistence
- âœ… **Phase 3**: Unified Provider Interface
- âœ… **Phase 4**: Multi-Cloud Support (AWS, Azure, GCP, Hyper-V)

---

## ðŸ“¦ Package Contents

The distribution package is organized into two main directories:

### bin/ Directory - Binaries
- `hypervisord` - Main daemon server (20MB, optimized)
- `hyperctl` - CLI management tool (15MB, optimized)
- `hyperexport` - Standalone export utility (14MB, optimized)

**Note**: Binaries are stripped and optimized (30% smaller than debug builds)

### docs/ Directory - Configuration and Documentation
- `config.example.yaml` - Complete configuration template
- `hypervisord.service` - Systemd service file
- `README.md` - Project overview
- `DEPLOYMENT.md` - This deployment guide
- `MULTI_CLOUD_GUIDE.md` - Multi-cloud provider setup
- `API_REFERENCE.md` - Complete API documentation

### Root Directory
- `install.sh` - Automated installation script
- `INSTALL.txt` - Quick installation instructions

---

## ðŸš€ Quick Start (5 Minutes)

### 1. Extract Distribution Package
```bash
tar -xzf hypersdk-0.2.0-linux-amd64.tar.gz
cd hypersdk-0.2.0-linux-amd64
```

### 2. Copy Example Configuration
```bash
cp docs/config.example.yaml config.yaml
```

### 3. Configure vCenter (Required)
Edit `config.yaml`:
```yaml
vcenter_url: "https://vcenter.yourcompany.com"
username: "admin@vsphere.local"
password: "your-secure-password"
insecure: false  # Set true for self-signed certs
```

### 4. Start the Daemon
```bash
./bin/hypervisord --config config.yaml
```

### 5. Verify Installation
```bash
# Check daemon status
curl http://localhost:8080/health

# List VMs
./bin/hyperctl list

# View React dashboard
open http://localhost:8080/web/dashboard/
# or
open http://localhost:8080/
```

---

## ðŸ“¤ HyperExport - Standalone Export Tool

HyperExport is a powerful standalone tool for exporting VMs with both interactive and non-interactive modes.

### Binary Size
- **Optimized Size**: 14MB (stripped symbols)
- **30% smaller** than previous versions

### Quick Start

#### Interactive Mode (Beautiful UI)
```bash
# Set vSphere credentials
export GOVC_URL='https://vcenter.example.com/sdk'
export GOVC_USERNAME='administrator@vsphere.local'
export GOVC_PASSWORD='your-password'
export GOVC_INSECURE=1

# Launch interactive export
./bin/hyperexport

# The interactive wizard will:
# 1. Connect to vSphere
# 2. Discover all VMs
# 3. Display selection menu with search
# 4. Show VM details (CPU, memory, storage)
# 5. Offer graceful shutdown option
# 6. Export with real-time progress
# 7. Display summary with files and sizes
```

#### Non-Interactive Mode (Scripting)
```bash
# Simple VM export
./bin/hyperexport -vm "/datacenter/vm/web-server-01"

# Export as compressed OVA
./bin/hyperexport -vm myvm -format ova -compress

# Batch export from file
cat > production-vms.txt <<EOF
/datacenter/vm/web-01
/datacenter/vm/web-02
/datacenter/vm/db-01
EOF

./bin/hyperexport -batch production-vms.txt -format ova -compress

# Full production export with all features
./bin/hyperexport \
  -vm critical-vm \
  -output /backup/$(date +%Y%m%d) \
  -format ova \
  -compress \
  -power-off \
  -verify \
  -parallel 8 \
  -quiet
```

### Command-Line Flags Reference

| Flag | Type | Default | Description |
|------|------|---------|-------------|
| `-vm` | string | - | VM name/path (skips interactive selection) |
| `-provider` | string | `vsphere` | Provider type (vsphere, aws, azure, gcp, hyperv) |
| `-output` | string | `./export-<vmname>` | Output directory |
| `-format` | string | `ovf` | Export format: `ovf` or `ova` |
| `-compress` | bool | `false` | Enable gzip compression for OVA |
| `-verify` | bool | `false` | SHA256 checksum validation |
| `-dry-run` | bool | `false` | Preview export without executing |
| `-batch` | string | - | File containing VM list (one per line) |
| `-filter` | string | - | Filter VMs by tag (format: key=value) |
| `-folder` | string | - | Filter VMs by folder path |
| `-power-off` | bool | `false` | Auto power-off VM before export |
| `-parallel` | int | `4` | Number of parallel downloads |
| `-quiet` | bool | `false` | Minimal output for scripting |
| `-version` | bool | `false` | Show version and exit |

### Usage Examples

#### 1. Development/Testing

**Interactive exploration:**
```bash
# Explore available VMs
./bin/hyperexport

# Dry-run to preview
./bin/hyperexport -folder /Test -dry-run
```

**Output:**
```
Dry-run mode: Export preview
  VM: test-vm-01
  Format: ovf
  Compression: false
  Output: ./export-test-vm-01
  Estimated Size: 10.5 GiB
```

#### 2. Production Backups

**Daily automated backup:**
```bash
#!/bin/bash
# /opt/scripts/daily-backup.sh

DATE=$(date +%Y%m%d)
BACKUP_DIR="/mnt/backup/$DATE"

./bin/hyperexport \
  -batch /etc/hyperexport/production-vms.txt \
  -output "$BACKUP_DIR" \
  -format ova \
  -compress \
  -verify \
  -power-off \
  -quiet >> /var/log/hyperexport.log 2>&1

# Check exit code
if [ $? -eq 0 ]; then
    echo "$DATE: Backup successful" >> /var/log/hyperexport.log
else
    echo "$DATE: Backup failed" >> /var/log/hyperexport.log
    exit 1
fi
```

**Cron job:**
```bash
# Export production VMs nightly at 2 AM
0 2 * * * /opt/scripts/daily-backup.sh
```

#### 3. Emergency Recovery

**Quick VM backup before maintenance:**
```bash
# Emergency backup with auto power-off
./bin/hyperexport -vm critical-database \
  -format ova \
  -compress \
  -power-off \
  -verify \
  -output /emergency-backup
```

#### 4. Migration Preparation

**Export VMs by folder:**
```bash
# Export all VMs in specific folder
./bin/hyperexport -folder /Production/WebServers -dry-run

# After review, perform actual export
./bin/hyperexport -folder /Production/WebServers \
  -format ova \
  -compress \
  -batch
```

#### 5. High-Performance Export

**Maximize throughput:**
```bash
# Use 8 parallel downloads
./bin/hyperexport -vm large-vm \
  -parallel 8 \
  -format ova \
  -compress
```

### Batch File Format

**Simple list** (`vms.txt`):
```
/datacenter/vm/web-01
/datacenter/vm/web-02
/datacenter/vm/db-01
```

**With comments** (lines starting with # are ignored):
```
# Production web servers
/datacenter/vm/web-01
/datacenter/vm/web-02

# Database servers
/datacenter/vm/db-01
/datacenter/vm/db-02

# This VM is disabled
# /datacenter/vm/old-vm
```

### Output Structure

**OVF Format** (default):
```
export-myvm/
â”œâ”€â”€ myvm.ovf           # OVF descriptor
â”œâ”€â”€ myvm.mf            # Manifest file
â”œâ”€â”€ myvm-disk1.vmdk    # Virtual disk 1
â”œâ”€â”€ myvm-disk2.vmdk    # Virtual disk 2 (if multiple disks)
â””â”€â”€ checksums.txt      # SHA256 hashes (if -verify used)
```

**OVA Format** (with `-format ova`):
```
export-myvm/
â”œâ”€â”€ myvm.ova           # TAR archive containing all OVF files
â””â”€â”€ checksums.txt      # SHA256 hash of OVA (if -verify used)
```

**OVA Compressed** (with `-format ova -compress`):
```
export-myvm/
â”œâ”€â”€ myvm.ova           # Gzip-compressed TAR archive (30-50% smaller)
â””â”€â”€ checksums.txt      # SHA256 hash
```

### Verification

When using `-verify`, checksums are calculated and saved:

**checksums.txt** (OVF format):
```
a1b2c3d4e5f6789... myvm.ovf
1234567890abcdef... myvm-disk1.vmdk
fedcba0987654321... myvm-disk2.vmdk
```

**checksums.txt** (OVA format):
```
9876543210fedcba... myvm.ova
```

**Verify manually:**
```bash
# Verify checksums
cd export-myvm
sha256sum -c checksums.txt
```

### Integration with Scripts

**Python integration:**
```python
#!/usr/bin/env python3
import subprocess
import sys
from datetime import datetime

def export_vm(vm_name, output_dir):
    """Export VM using hyperexport"""
    cmd = [
        './bin/hyperexport',
        '-vm', vm_name,
        '-output', output_dir,
        '-format', 'ova',
        '-compress',
        '-verify',
        '-quiet'
    ]

    result = subprocess.run(cmd, capture_output=True, text=True)

    if result.returncode == 0:
        print(f"âœ“ {vm_name}: Export successful")
        return True
    else:
        print(f"âœ— {vm_name}: {result.stderr}", file=sys.stderr)
        return False

# Export multiple VMs
vms = ['/datacenter/vm/web-01', '/datacenter/vm/web-02']
backup_dir = f'/backup/{datetime.now().strftime("%Y%m%d")}'

for vm in vms:
    export_vm(vm, backup_dir)
```

**Shell script with error handling:**
```bash
#!/bin/bash
set -euo pipefail

VM_NAME="$1"
OUTPUT_DIR="${2:-./export-$(date +%Y%m%d)}"

echo "Starting export: $VM_NAME"

if ./bin/hyperexport \
    -vm "$VM_NAME" \
    -output "$OUTPUT_DIR" \
    -format ova \
    -compress \
    -verify \
    -quiet; then

    echo "âœ“ Export completed: $OUTPUT_DIR"

    # Optional: Upload to remote storage
    # rsync -avz "$OUTPUT_DIR" backup-server:/backups/

else
    echo "âœ— Export failed for $VM_NAME" >&2
    exit 1
fi
```

### Multi-Provider Support (Preview)

**Coming soon** - Support for additional cloud providers:

```bash
# AWS EC2
./bin/hyperexport -provider aws -vm i-1234567890abcdef

# Azure
./bin/hyperexport -provider azure -vm my-azure-vm

# GCP
./bin/hyperexport -provider gcp -vm my-gcp-instance

# Hyper-V
./bin/hyperexport -provider hyperv -vm my-hyperv-vm
```

### Performance Comparison

| Configuration | Export Time | Size | Notes |
|---------------|-------------|------|-------|
| OVF (uncompressed) | Baseline | 100% | Fastest export |
| OVA (uncompressed) | +2-3 min | 100% | TAR packaging overhead |
| OVA (compressed) | +5-8 min | 50-70% | Gzip compression |
| OVA (compressed, parallel=8) | +4-6 min | 50-70% | Optimal for large VMs |

**Recommendations:**
- **Small VMs (<50GB)**: Use `-format ova -compress`
- **Large VMs (>100GB)**: Use `-format ova -compress -parallel 8`
- **Quick testing**: Use default OVF format
- **Long-term storage**: Use `-format ova -compress -verify`

### Troubleshooting

**Problem**: Connection timeout
```bash
# Solution: Increase timeout (not implemented yet)
export GOVC_TIMEOUT=600  # 10 minutes
```

**Problem**: Insufficient disk space
```bash
# Solution: Check before export
df -h /backup
./bin/hyperexport -vm myvm -dry-run  # Preview size
```

**Problem**: Permission denied
```bash
# Solution: Check output directory permissions
mkdir -p /backup/exports
chmod 755 /backup/exports
```

**Problem**: VM is locked
```bash
# Solution: Check for snapshots or other operations
# Use vSphere client to release locks
```

### Best Practices

1. **Always use `-verify`** for production exports
2. **Use `-dry-run`** to preview before large exports
3. **Use batch mode** for multiple VMs (more efficient connection reuse)
4. **Enable compression** for long-term storage
5. **Use `-quiet`** in cron jobs and scripts
6. **Monitor disk space** before large exports
7. **Test restore** from backups regularly
8. **Store checksums** with exports for integrity verification

---

## ðŸ”§ Production Deployment

### System Requirements

**Minimum**:
- CPU: 2 cores
- RAM: 2GB
- Disk: 50GB (plus storage for exports)
- OS: Linux (Ubuntu 20.04+, RHEL 8+, Fedora 35+)

**Recommended**:
- CPU: 4+ cores
- RAM: 8GB
- Disk: 500GB SSD
- OS: Ubuntu 22.04 LTS or RHEL 9

### Network Requirements
- Outbound HTTPS (443) to vCenter/cloud providers
- Inbound HTTP (8080) for API/dashboard
- Inbound HTTPS (8443) for TLS (optional)

---

## ðŸ“ Configuration

### Essential Settings

```yaml
# vCenter Connection
vcenter_url: "https://vcenter.example.com"
username: "automation@vsphere.local"
password: "SecurePassword123!"
insecure: false
timeout: 3600s

# Export Performance
download_workers: 3
chunk_size: 33554432  # 32MB
retry_attempts: 3
retry_delay: 5s

# Daemon API
daemon_addr: "0.0.0.0:8080"

# Logging
log_level: "info"  # debug, info, warn, error
progress_style: "bar"
show_eta: true
```

### Connection Pooling (Phase 1.1)

```yaml
connection_pool:
  enabled: true
  max_connections: 5
  idle_timeout: 5m
  health_check_interval: 30s
```

**Benefits**:
- 30-40% faster concurrent exports
- Reduced vCenter load
- Automatic connection health monitoring

### Webhook Notifications (Phase 1.2)

```yaml
webhooks:
  # Slack notifications
  - url: "https://hooks.slack.com/services/YOUR/WEBHOOK/URL"
    events:
      - "job.started"
      - "job.completed"
      - "job.failed"
    timeout: 10s
    retry: 3
    enabled: true

  # Custom API endpoint
  - url: "https://api.yourcompany.com/vm-exports"
    events: ["*"]  # All events
    headers:
      Authorization: "Bearer your-api-token"
      X-Environment: "production"
    timeout: 15s
    retry: 5
    enabled: true
```

**Supported Events**:
- `job.started` - Export job begins
- `job.completed` - Export successful
- `job.failed` - Export failed
- `job.progress` - Progress updates (if enabled)
- `job.cancelled` - Job cancelled by user

### Schedule Persistence (Phase 2.3)

```yaml
database_path: "./hypersdk.db"
```

**Features**:
- Schedules persist across daemon restarts
- Execution history tracking
- SQLite-based (no external DB required)

---

## ðŸŒ¥ï¸ Multi-Cloud Configuration

### AWS EC2 Export (Phase 4.1)

```yaml
aws:
  enabled: true
  region: "us-east-1"
  access_key: "AKIAIOSFODNN7EXAMPLE"
  secret_key: "wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY"
  s3_bucket: "vm-exports"
  export_format: "vmdk"  # vmdk, vhd, raw
```

**Usage Example**:
```bash
curl -X POST http://localhost:8080/jobs/submit \
  -H "Content-Type: application/json" \
  -d '{
    "provider": "aws",
    "vm_path": "i-1234567890abcdef0",
    "output_dir": "/exports",
    "format": "vmdk"
  }'
```

### Azure VHD Export (Phase 4.2)

```yaml
azure:
  enabled: true
  subscription_id: "00000000-0000-0000-0000-000000000000"
  tenant_id: "00000000-0000-0000-0000-000000000000"
  client_id: "00000000-0000-0000-0000-000000000000"
  client_secret: "your-client-secret"
  resource_group: "vm-exports-rg"
  location: "eastus"
  storage_account: "vmexportsstorage"
  container: "vhd-exports"
  export_format: "vhd"
```

### GCP Export (Phase 4.3)

```yaml
gcp:
  enabled: true
  project_id: "my-gcp-project"
  zone: "us-central1-a"
  region: "us-central1"
  credentials_json: "/path/to/service-account-key.json"
  gcs_bucket: "vm-exports"
  export_format: "vmdk"
```

### Hyper-V Export (Phase 4.4)

```yaml
hyperv:
  enabled: true
  host: "hyperv-server.example.com"
  username: "Administrator"
  password: "HyperVPassword!"
  use_winrm: true
  winrm_port: 5985
  use_https: false
  export_format: "vhdx"
```

---

## ðŸ“Š Web Dashboard

HyperSDK includes a modern React/TypeScript dashboard with real-time monitoring:

**Features:**
- **Real-time Monitoring**: WebSocket-based live metrics updates
- **Interactive Charts**: Historical data visualization with Recharts
- **Job Management**: View, filter, sort, and cancel jobs
- **Alert System**: Real-time alerts and notifications
- **Provider Analytics**: Multi-cloud provider comparison
- **Responsive Design**: Works on desktop and mobile devices

**Access:**
```
http://localhost:8080/web/dashboard/
```

Or simply visit:
```
http://localhost:8080/
```

### Disable Web Dashboard

To run in API-only mode without the web dashboard:

```yaml
# config.yaml
web:
  disabled: true
```

### Dashboard Features

**System Overview:**
- Active/completed/failed job counts
- Queue length and pending jobs
- Memory and CPU usage
- WebSocket client connections
- System uptime

**Real-time Charts:**
- Job activity over time (line chart)
- System resources (memory, CPU, goroutines)
- Jobs by provider (pie chart)
- Provider comparison

**Job Management:**
- Recent jobs table with sorting/filtering
- Job progress tracking
- Cancel running jobs
- View job details and errors

**Alerts:**
- System health alerts
- Job failure notifications
- Resource usage warnings

---

## ðŸ” Security Hardening

### 1. Enable TLS

```yaml
daemon_addr: "0.0.0.0:8443"
tls:
  enabled: true
  cert_file: "/etc/hypersdk/tls/server.crt"
  key_file: "/etc/hypersdk/tls/server.key"
```

### 2. Configure Authentication

```yaml
auth:
  enabled: true
  session_timeout: 24h
  # Add users via API or config
```

### 3. Enable RBAC

```yaml
rbac:
  enabled: true
  policy_file: "/etc/hypersdk/rbac-policy.yaml"
```

### 4. Secure Secrets

**Option 1: Environment Variables**
```bash
export VCENTER_PASSWORD="secure-password"
export AWS_SECRET_KEY="aws-secret"
./bin/hypervisord --config config.yaml
```

**Option 2: Secrets Management**
```yaml
secrets:
  backend: "vault"  # vault, aws-secrets, azure-keyvault
  vault_addr: "https://vault.example.com"
  vault_token: "s.xxxxxxxxxxxx"
```

---

## ðŸ³ Docker Deployment

### Build Docker Image

```bash
docker build -t hypersdk:latest .
```

### Run with Docker

```bash
docker run -d \
  --name hypersdk \
  -p 8080:8080 \
  -v $(pwd)/config.yaml:/app/config.yaml \
  -v $(pwd)/exports:/exports \
  hypersdk:latest
```

### Docker Compose

```yaml
version: '3.8'
services:
  hypersdk:
    image: hypersdk:latest
    ports:
      - "8080:8080"
    volumes:
      - ./config.yaml:/app/config.yaml
      - ./exports:/exports
      - ./data:/app/data
    environment:
      - LOG_LEVEL=info
    restart: unless-stopped
```

---

## â˜¸ï¸ Kubernetes Deployment

### Deployment Manifest

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: hypersdk
  namespace: vm-management
spec:
  replicas: 2
  selector:
    matchLabels:
      app: hypersdk
  template:
    metadata:
      labels:
        app: hypersdk
    spec:
      containers:
      - name: hypersdk
        image: hypersdk:latest
        ports:
        - containerPort: 8080
        volumeMounts:
        - name: config
          mountPath: /app/config.yaml
          subPath: config.yaml
        - name: exports
          mountPath: /exports
        env:
        - name: LOG_LEVEL
          value: "info"
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
          limits:
            memory: "8Gi"
            cpu: "4000m"
      volumes:
      - name: config
        configMap:
          name: hypersdk-config
      - name: exports
        persistentVolumeClaim:
          claimName: hypersdk-exports
```

### Service & Ingress

```yaml
apiVersion: v1
kind: Service
metadata:
  name: hypersdk
spec:
  selector:
    app: hypersdk
  ports:
  - port: 8080
    targetPort: 8080
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: hypersdk
  annotations:
    cert-manager.io/cluster-issuer: letsencrypt-prod
spec:
  tls:
  - hosts:
    - hypersdk.example.com
    secretName: hypersdk-tls
  rules:
  - host: hypersdk.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: hypersdk
            port:
              number: 8080
```

---

## ðŸ”„ Systemd Service

### Create Service File

```bash
sudo tee /etc/systemd/system/hypervisord.service > /dev/null <<EOF
[Unit]
Description=HyperSDK VM Export Daemon
After=network.target

[Service]
Type=simple
User=hypersdk
Group=hypersdk
WorkingDirectory=/opt/hypersdk
ExecStart=/opt/hypersdk/bin/hypervisord --config /etc/hypersdk/config.yaml
Restart=on-failure
RestartSec=10
StandardOutput=journal
StandardError=journal
SyslogIdentifier=hypervisord

# Security
NoNewPrivileges=true
PrivateTmp=true
ProtectSystem=strict
ProtectHome=true
ReadWritePaths=/opt/hypersdk/data /var/log/hypersdk

[Install]
WantedBy=multi-user.target
EOF
```

### Enable and Start

```bash
sudo systemctl daemon-reload
sudo systemctl enable hypervisord
sudo systemctl start hypervisord
sudo systemctl status hypervisord
```

### View Logs

```bash
sudo journalctl -u hypervisord -f
```

---

## ðŸ“Š Monitoring Setup

### Prometheus Integration

HyperSDK exposes metrics at `/metrics`:

```yaml
# prometheus.yml
scrape_configs:
  - job_name: 'hypersdk'
    static_configs:
      - targets: ['localhost:8080']
    metrics_path: '/metrics'
```

**Key Metrics**:
- `hypersdk_jobs_total` - Total jobs by status
- `hypersdk_job_duration_seconds` - Export duration
- `hypersdk_queue_length` - Pending jobs
- `hypersdk_http_requests_total` - API requests
- `hypersdk_memory_bytes` - Memory usage
- `hypersdk_goroutines` - Active goroutines

### Grafana Dashboards

Import pre-built dashboards from `monitoring/grafana/`:
- `hypersdk-overview.json` - System overview
- `job-performance.json` - Job metrics
- `system-resources.json` - Resource usage

```bash
# Start monitoring stack
cd monitoring
docker-compose up -d

# Access Grafana
open http://localhost:3000
# Login: admin / admin
```

---

## ðŸ§ª Testing the Deployment

### 1. Health Check

```bash
curl http://localhost:8080/health
# Expected: {"status":"ok","version":"0.2.0"}
```

### 2. List VMs

```bash
curl http://localhost:8080/vms
```

### 3. Test Export (vSphere)

```bash
curl -X POST http://localhost:8080/jobs/submit \
  -H "Content-Type: application/json" \
  -d '{
    "name": "test-export",
    "vm_path": "/Datacenter/vm/test-vm",
    "output_dir": "/exports",
    "format": "ova",
    "compress": true
  }'
```

### 4. Test Scheduled Job

```bash
curl -X POST http://localhost:8080/schedules \
  -H "Content-Type: application/json" \
  -d '{
    "id": "daily-backup",
    "name": "Daily VM Backup",
    "schedule": "0 2 * * *",
    "enabled": true,
    "job_template": {
      "vm_path": "/Datacenter/vm/production-*",
      "output_dir": "/backups",
      "format": "ova",
      "compress": true
    }
  }'
```

---

## ðŸ”§ Troubleshooting

### Daemon Won't Start

```bash
# Check logs
./bin/hypervisord --config config.yaml 2>&1 | tee startup.log

# Common issues:
# 1. Port already in use
sudo lsof -i :8080

# 2. Config file not found
ls -l config.yaml

# 3. Permission issues
chmod 644 config.yaml
```

### Connection Pool Issues

```bash
# Enable debug logging
log_level: "debug"

# Check pool stats via API
curl http://localhost:8080/metrics | grep connection_pool
```

### Webhook Not Firing

```bash
# Test webhook manually
curl -X POST https://hooks.slack.com/services/YOUR/WEBHOOK/URL \
  -H "Content-Type: application/json" \
  -d '{"text":"Test from HyperSDK"}'

# Check webhook logs
curl http://localhost:8080/webhooks/status
```

### Schedule Not Persisting

```bash
# Check database file
ls -l hypersdk.db

# Verify schedules in DB
sqlite3 hypersdk.db "SELECT * FROM scheduled_jobs;"

# Force schedule reload
curl -X POST http://localhost:8080/schedules/reload
```

---

## ðŸ“ˆ Performance Tuning

### For High-Throughput Environments

```yaml
# Increase workers
download_workers: 10

# Larger chunks
chunk_size: 67108864  # 64MB

# More connections
connection_pool:
  max_connections: 10

# Disable progress updates
progress_style: "quiet"
```

### For Resource-Constrained Systems

```yaml
# Fewer workers
download_workers: 2

# Smaller chunks
chunk_size: 16777216  # 16MB

# Limited connections
connection_pool:
  max_connections: 2
```

---

## ðŸ”„ Upgrade Guide

### From v0.1.x to v0.2.0

1. **Backup Configuration**
```bash
cp config.yaml config.yaml.backup
cp hypersdk.db hypersdk.db.backup
```

2. **Stop Old Version**
```bash
sudo systemctl stop hypervisord
```

3. **Replace Binaries**
```bash
sudo cp bin/* /opt/hypersdk/bin/
```

4. **Update Configuration**
```bash
# Add new Phase 4 sections to config.yaml
# See config.example.yaml for reference
```

5. **Start New Version**
```bash
sudo systemctl start hypervisord
sudo systemctl status hypervisord
```

6. **Verify**
```bash
./bin/hypervisord --version
# Should show: v0.2.0

curl http://localhost:8080/health
```

---

## ðŸ†˜ Support & Resources

### Documentation
- [Multi-Cloud Guide](MULTI_CLOUD_GUIDE.md)
- [API Reference](API_REFERENCE.md)
- [Example Configurations](examples/)

### Community
- GitHub Issues: https://github.com/your-org/hypersdk/issues
- Discussions: https://github.com/your-org/hypersdk/discussions

### Commercial Support
- Email: support@hypersdk.io
- Documentation: https://docs.hypersdk.io

---

## âœ… Deployment Checklist

- [ ] Downloaded/compiled binaries
- [ ] Created `config.yaml` from example
- [ ] Configured vCenter credentials
- [ ] Tested vCenter connectivity
- [ ] Enabled connection pooling
- [ ] Configured webhooks (optional)
- [ ] Set up scheduled jobs (optional)
- [ ] Configured cloud providers (optional)
- [ ] Enabled TLS/authentication
- [ ] Set up monitoring (Prometheus/Grafana)
- [ ] Created systemd service
- [ ] Tested export functionality
- [ ] Configured backups
- [ ] Documented deployment

---

**Deployment complete! Your HyperSDK instance is ready for production use.** ðŸŽ‰
